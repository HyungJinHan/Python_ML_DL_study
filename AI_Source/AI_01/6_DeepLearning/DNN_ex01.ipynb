{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_gate(x1, x2):\n",
    "  w1 = 0.5\n",
    "  w2 = 0.5\n",
    "  b = 0.7\n",
    "\n",
    "  result = x1 * w1 + x2 * w2 + b\n",
    "\n",
    "  if result <= 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND_gate(1, 1)\n",
    "# x1 = 0, x2 = 0 : y = 0\n",
    "# x1 = 0, x2 = 1 : y = 0\n",
    "# x1 = 1, x2 = 0 : y = 0\n",
    "# x1 = 1, x2 = 1 : y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND_gate(x1, x2):\n",
    "  w1 = -0.5\n",
    "  w2 = -0.5\n",
    "  b = 0.7\n",
    "\n",
    "  result = x1 * w1 + x2 * w2 + b\n",
    "\n",
    "  if result <= 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND_gate(1, 1)\n",
    "# x1 = 0, x2 = 0 : y = 1\n",
    "# x1 = 0, x2 = 1 : y = 1\n",
    "# x1 = 1, x2 = 0 : y = 1\n",
    "# x1 = 1, x2 = 1 : y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_gate(x1, x2):\n",
    "  w1 = 0.6\n",
    "  w2 = 0.6\n",
    "  b = 0.5\n",
    "\n",
    "  result = x1 * w1 + x2 * w2 + b\n",
    "\n",
    "  if result <= 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_gate(1, 1)\n",
    "# x1 = 0, x2 = 0 : y = 0\n",
    "# x1 = 0, x2 = 1 : y = 1\n",
    "# x1 = 1, x2 = 0 : y = 1\n",
    "# x1 = 1, x2 = 1 : y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논리게이트 (Logic gate) 클래스 구현\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "  delta_x = 1e-4 # 0.0001\n",
    "  grad = np.zeros_like(x)\n",
    "\n",
    "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "  while not it.finished:\n",
    "    idx = it.multi_index\n",
    "    tmp_val = x[idx]\n",
    "    x[idx] = float(tmp_val) + delta_x\n",
    "    fx1 = f(x) # f(x + delta_x)\n",
    "\n",
    "    x[idx] = float(tmp_val) - delta_x\n",
    "    fx2 = f(x) # f(x - delta_x)\n",
    "    grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "\n",
    "    x[idx] = tmp_val\n",
    "    it.iternext()\n",
    "\n",
    "  return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "  def __init__(self, gate_name, xdata, tdata):\n",
    "    self.name = gate_name\n",
    "    self.xdata = xdata.reshape(4, 2) # 입력 데이터 초기화\n",
    "    self.tdata = tdata.reshape(4, 1) # 정답 데이터 초기화\n",
    "    self.W = np.random.rand(self.xdata.shape[1], 1) # 가중치 W 초기화\n",
    "    self.b = np.random.rand(1) # 바이어스 b 초기화\n",
    "    self.learning_rate = 1e-2 # 학습률 learning rate 초기화\n",
    "\n",
    "  def loss_func(self):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    z = np.dot(self.xdata, self.W) + self.b\n",
    "    y = sigmoid(z)\n",
    "    return -np.sum(self.tdata * np.log(y + delta) + (1 - self.tdata) * np.log((1 - y) + delta))\n",
    "\n",
    "  def train(self): # 경사하강법 이용하여 W, b 업데이트\n",
    "    f = lambda x : self.loss_func()\n",
    "    print('Initial Loss Value =', self.loss_func())\n",
    "\n",
    "    for step in range(10001):\n",
    "      self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "      self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "\n",
    "      if step % 1000 == 0:\n",
    "        print('step =', step, 'Loss Value =', self.loss_func())\n",
    "\n",
    "  def predict(self, input_data): # 미래 값 예측\n",
    "    z = np.dot(input_data, self.W) + self.b\n",
    "    y = sigmoid(z)\n",
    "\n",
    "    if y > 0.5:\n",
    "      result = 1\n",
    "    else:\n",
    "      result = 0\n",
    "    return y, result\n",
    "\n",
    "    # 정확도 예측 함수 (추가 내용)\n",
    "  def accuracy(self, test_xdata, test_tdata):\n",
    "    matched_list = []\n",
    "    not_matched_list = []\n",
    "\n",
    "    for index in range(len(xdata)):\n",
    "      (real_val, logical_val) = self.predict(test_xdata[index])\n",
    "\n",
    "      if logical_val == test_tdata[index]:\n",
    "        matched_list.append(index)\n",
    "      else:\n",
    "        not_matched_list.append(index)\n",
    "\n",
    "      accuracy_val = len(matched_list) / len(test_xdata)\n",
    "\n",
    "    return accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss Value = 4.097141319904998\n",
      "step = 0 Loss Value = 4.046508046234326\n",
      "step = 1000 Loss Value = 0.9890527100673177\n",
      "step = 2000 Loss Value = 0.6526659776666796\n",
      "step = 3000 Loss Value = 0.4871476671056258\n",
      "step = 4000 Loss Value = 0.3875400594865026\n",
      "step = 5000 Loss Value = 0.321009986844354\n",
      "step = 6000 Loss Value = 0.27351442588371494\n",
      "step = 7000 Loss Value = 0.2379726406911565\n",
      "step = 8000 Loss Value = 0.21041853484698564\n",
      "step = 9000 Loss Value = 0.1884581686487931\n",
      "step = 10000 Loss Value = 0.17056234242710525\n",
      "[0 0] = 0\n",
      "[0 1] = 0\n",
      "[1 0] = 0\n",
      "[1 1] = 1\n",
      "Accuracy => 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND 논리 게이트 검증\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "\n",
    "AND_obj = LogicGate('AND_GATE', xdata, tdata)\n",
    "AND_obj.train()\n",
    "\n",
    "s3 = []\n",
    "\n",
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_xdata:\n",
    "  (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "  s3.append(logical_val)\n",
    "  print(input_data, '=', logical_val)\n",
    "\n",
    "test_tdata = np.array([0, 0, 0, 1])\n",
    "accuracy_ret = AND_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy =>', accuracy_ret)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss Value = 2.1627342975986994\n",
      "step = 0 Loss Value = 2.1478102424225147\n",
      "step = 1000 Loss Value = 0.6957962026058723\n",
      "step = 2000 Loss Value = 0.422466815462085\n",
      "step = 3000 Loss Value = 0.29895058643669226\n",
      "step = 4000 Loss Value = 0.22974723535138117\n",
      "step = 5000 Loss Value = 0.1858880952840598\n",
      "step = 6000 Loss Value = 0.15576159034410422\n",
      "step = 7000 Loss Value = 0.13386076511934294\n",
      "step = 8000 Loss Value = 0.11725587697997442\n",
      "step = 9000 Loss Value = 0.10425168063308558\n",
      "step = 10000 Loss Value = 0.09380215259289565\n",
      "[0 0] = 0\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 1\n",
      "Accuracy => 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR 논리 게이트 검증\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "\n",
    "OR_obj = LogicGate('OR_GATE', xdata, tdata)\n",
    "OR_obj.train()\n",
    "\n",
    "s1 = []\n",
    "\n",
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_xdata:\n",
    "  (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "  s1.append(logical_val)\n",
    "  print(input_data, '=', logical_val)\n",
    "\n",
    "test_tdata = np.array([0, 1, 1, 1])\n",
    "accuracy_OR = OR_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy =>', accuracy_ret)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss Value = 2.5082164527254065\n",
      "step = 0 Loss Value = 2.50281709075056\n",
      "step = 1000 Loss Value = 1.0144836292659143\n",
      "step = 2000 Loss Value = 0.663405631402167\n",
      "step = 3000 Loss Value = 0.49317181780445124\n",
      "step = 4000 Loss Value = 0.39139807930521703\n",
      "step = 5000 Loss Value = 0.3236863724816995\n",
      "step = 6000 Loss Value = 0.27547549691849826\n",
      "step = 7000 Loss Value = 0.23946855333494593\n",
      "step = 8000 Loss Value = 0.21159550647681694\n",
      "step = 9000 Loss Value = 0.18940728426436942\n",
      "step = 10000 Loss Value = 0.17134322781213632\n",
      "[0 0] = 1\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 0\n",
      "Accuracy => 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAND 논리 게이트 검증\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "\n",
    "NAND_obj = LogicGate('NAND_GATE', xdata, tdata)\n",
    "NAND_obj.train()\n",
    "\n",
    "s2 = []\n",
    "\n",
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_xdata:\n",
    "  (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "  s2.append(logical_val)\n",
    "  print(input_data, '=', logical_val)\n",
    "\n",
    "test_tdata = np.array([1, 1, 1, 0])\n",
    "accuracy_NAND = NAND_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy =>', accuracy_ret)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss Value = 4.632971254960649\n",
      "step = 0 Loss Value = 4.544148577338901\n",
      "step = 1000 Loss Value = 0.47439813873797443\n",
      "step = 2000 Loss Value = 0.23917218570756738\n",
      "step = 3000 Loss Value = 0.158038331843746\n",
      "step = 4000 Loss Value = 0.11758749627740012\n",
      "step = 5000 Loss Value = 0.09348348652347777\n",
      "step = 6000 Loss Value = 0.07752183458524006\n",
      "step = 7000 Loss Value = 0.06618769560590461\n",
      "step = 8000 Loss Value = 0.057729989579032706\n",
      "step = 9000 Loss Value = 0.051180238305587246\n",
      "step = 10000 Loss Value = 0.045959987088998816\n",
      "[0 0] = 0\n",
      "[0 1] = 0\n",
      "[1 0] = 0\n",
      "[1 1] = 1\n",
      "Accuracy => 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0, 1], [1, 1], [1, 1], [1, 0]], [0, 0, 0, 1])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XOR 논리 게이트 검증\n",
    "test_xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "s4 = []\n",
    "\n",
    "for i in range(len(test_xdata)):\n",
    "  s4.append([s1[i], s2[i]])\n",
    "\n",
    "xdata = np.array(s4)\n",
    "tdata = np.array(s3)\n",
    "\n",
    "XOR_obj = LogicGate('XOR_GATE', xdata, tdata)\n",
    "XOR_obj.train()\n",
    "\n",
    "for input_data in test_xdata:\n",
    "  (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "  print(input_data, '=', logical_val)\n",
    "\n",
    "test_tdata = np.array([0, 1, 1, 0])\n",
    "accuracy_XOR = AND_obj.accuracy(test_xdata, test_tdata)\n",
    "print('Accuracy =>', accuracy_ret)\n",
    "s4, s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수업 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss Value = 3.543843596024649\n",
      "step = 0 Loss Value = 3.506341247543432\n",
      "step = 1000 Loss Value = 0.9982559708667044\n",
      "step = 2000 Loss Value = 0.6565053790254414\n",
      "step = 3000 Loss Value = 0.489304058753386\n",
      "step = 4000 Loss Value = 0.38892294801351224\n",
      "step = 5000 Loss Value = 0.3219702549491572\n",
      "step = 6000 Loss Value = 0.27421854090121434\n",
      "step = 7000 Loss Value = 0.2385100299906905\n",
      "step = 8000 Loss Value = 0.2108415260364794\n",
      "step = 9000 Loss Value = 0.1887993864369201\n",
      "step = 10000 Loss Value = 0.170843157952384\n",
      "Initial Loss Value = 1.7282367429597987\n",
      "step = 0 Loss Value = 1.7256474521809166\n",
      "step = 1000 Loss Value = 0.7012125824034221\n",
      "step = 2000 Loss Value = 0.4245380915635876\n",
      "step = 3000 Loss Value = 0.3000193940277297\n",
      "step = 4000 Loss Value = 0.23039153023944747\n",
      "step = 5000 Loss Value = 0.18631589968955128\n",
      "step = 6000 Loss Value = 0.1560650545461346\n",
      "step = 7000 Loss Value = 0.134086617780177\n",
      "step = 8000 Loss Value = 0.11743020480822158\n",
      "step = 9000 Loss Value = 0.10439013707767344\n",
      "step = 10000 Loss Value = 0.0939146746581494\n",
      "Initial Loss Value = 2.5297653827568016\n",
      "step = 0 Loss Value = 2.5251052171209336\n",
      "step = 1000 Loss Value = 1.0222876052217618\n",
      "step = 2000 Loss Value = 0.6665989277966751\n",
      "step = 3000 Loss Value = 0.49495074296539254\n",
      "step = 4000 Loss Value = 0.3925336893603708\n",
      "step = 5000 Loss Value = 0.3244725712749421\n",
      "step = 6000 Loss Value = 0.27605074133665986\n",
      "step = 7000 Loss Value = 0.23990687678453582\n",
      "step = 8000 Loss Value = 0.21194008302689676\n",
      "step = 9000 Loss Value = 0.18968496238152974\n",
      "step = 10000 Loss Value = 0.17157155891249504\n",
      "[0 0] = 0\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 0\n"
     ]
    }
   ],
   "source": [
    "#XOR 논리게이트\n",
    "xdata = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "tdata = np.array([0,0,0,1])\n",
    "AND_obj = LogicGate('AND_GATE', xdata, tdata)\n",
    "AND_obj.train()\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata) \n",
    "OR_obj.train()\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata) \n",
    "NAND_obj.train()\n",
    "\n",
    "input_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "s1 = []\n",
    "s2 = []\n",
    "new_input_data = []\n",
    "final_output = []\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    s1 = NAND_obj.predict(input_data[index])\n",
    "    s2 = OR_obj.predict(input_data[index])\n",
    "\n",
    "    new_input_data.append(s1[-1])\n",
    "    new_input_data.append(s2[-1])\n",
    "\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
    "\n",
    "    final_output.append(logical_val)\n",
    "\n",
    "    new_input_data = []\n",
    "    \n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index], '=', final_output[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1d7460674a73418ab454bd6edfaf2f1a894e6aad421ddec5a5a37cc572abb49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
